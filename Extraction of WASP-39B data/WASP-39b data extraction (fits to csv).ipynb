{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d432abc-ef42-4f9c-986c-9ceb29092182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: jw01366-o004_t001_nirspec_clear-prism-s1600a1-sub512_x1dints.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU     362   ()      \n",
      "  1  INT_TIMES     1 BinTableHDU     24   21500R x 7C   [J, D, D, D, D, D, D]   \n",
      "  2  EXTRACT1D     1 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  3  EXTRACT1D     2 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  4  EXTRACT1D     3 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  5  EXTRACT1D     4 BinTableHDU    122   3200R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  6  ASDF          1 BinTableHDU     11   1R x 1C   [60846B]   \n"
     ]
    }
   ],
   "source": [
    "from astropy.io import fits\n",
    "\n",
    "# Open the file\n",
    "with fits.open('jw01366-o004_t001_nirspec_clear-prism-s1600a1-sub512_x1dints.fits') as hdul:\n",
    "    # List all extensions to see structure\n",
    "    hdul.info()\n",
    "    # This will show you what sections exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca8db373-5c2b-4561-8997-cc92278ead75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening FITS file: jw01366-o004_t001_nirspec_clear-prism-s1600a1-sub512_x1dints.fits\n",
      "\n",
      "======================================================================\n",
      "FITS FILE STRUCTURE\n",
      "======================================================================\n",
      "Filename: jw01366-o004_t001_nirspec_clear-prism-s1600a1-sub512_x1dints.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU     362   ()      \n",
      "  1  INT_TIMES     1 BinTableHDU     24   21500R x 7C   [J, D, D, D, D, D, D]   \n",
      "  2  EXTRACT1D     1 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  3  EXTRACT1D     2 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  4  EXTRACT1D     3 BinTableHDU    122   6100R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  5  EXTRACT1D     4 BinTableHDU    122   3200R x 27C   [J, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432D, 432J, 432D, 432D, 432D, 432D, 432D, 432D, J, J, D, D, D, D, D, D]   \n",
      "  6  ASDF          1 BinTableHDU     11   1R x 1C   [60846B]   \n",
      "\n",
      "======================================================================\n",
      "EXTRACTING INTEGRATION TIMES\n",
      "======================================================================\n",
      "Saved: wasp39_extracted_data\\integration_times.csv\n",
      "Shape: (21500, 7)\n",
      "Columns: ['integration_number', 'int_start_MJD_UTC', 'int_mid_MJD_UTC', 'int_end_MJD_UTC', 'int_start_BJD_TDB', 'int_mid_BJD_TDB', 'int_end_BJD_TDB']\n",
      "\n",
      "======================================================================\n",
      "EXTRACTING SPECTRA FROM ALL VERSIONS\n",
      "======================================================================\n",
      "\n",
      "--- EXTRACT1D Version 1 (HDU 2) ---\n",
      "Rows: 6100, Columns: 27\n",
      "Column names: ('INT_NUM', 'WAVELENGTH', 'FLUX', 'FLUX_ERROR', 'FLUX_VAR_POISSON')... (showing first 5)\n",
      "Saved: wasp39_extracted_data\\extract1d_version_1.csv\n",
      "Shape: (6100, 7786)\n",
      "Memory usage: 352.23 MB\n",
      "\n",
      "--- EXTRACT1D Version 2 (HDU 3) ---\n",
      "Rows: 6100, Columns: 27\n",
      "Column names: ('INT_NUM', 'WAVELENGTH', 'FLUX', 'FLUX_ERROR', 'FLUX_VAR_POISSON')... (showing first 5)\n",
      "Saved: wasp39_extracted_data\\extract1d_version_2.csv\n",
      "Shape: (6100, 7786)\n",
      "Memory usage: 352.23 MB\n",
      "\n",
      "--- EXTRACT1D Version 3 (HDU 4) ---\n",
      "Rows: 6100, Columns: 27\n",
      "Column names: ('INT_NUM', 'WAVELENGTH', 'FLUX', 'FLUX_ERROR', 'FLUX_VAR_POISSON')... (showing first 5)\n",
      "Saved: wasp39_extracted_data\\extract1d_version_3.csv\n",
      "Shape: (6100, 7786)\n",
      "Memory usage: 352.23 MB\n",
      "\n",
      "--- EXTRACT1D Version 4 (HDU 5) ---\n",
      "Rows: 3200, Columns: 27\n",
      "Column names: ('INT_NUM', 'WAVELENGTH', 'FLUX', 'FLUX_ERROR', 'FLUX_VAR_POISSON')... (showing first 5)\n",
      "Saved: wasp39_extracted_data\\extract1d_version_4.csv\n",
      "Shape: (3200, 7786)\n",
      "Memory usage: 184.78 MB\n",
      "\n",
      "======================================================================\n",
      "EXTRACTION COMPLETE\n",
      "======================================================================\n",
      "All files saved to: wasp39_extracted_data/\n",
      "\n",
      "Generated files:\n",
      "  - extract1d_version_1.csv (433.01 MB)\n",
      "  - extract1d_version_2.csv (432.95 MB)\n",
      "  - extract1d_version_3.csv (432.99 MB)\n",
      "  - extract1d_version_4.csv (227.25 MB)\n",
      "  - integration_times.csv (2.37 MB)\n",
      "\n",
      "======================================================================\n",
      "SAMPLE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Inspecting: wasp39_extracted_data\\extract1d_version_1.csv\n",
      "Shape: (6100, 7786)\n",
      "\n",
      "First few rows:\n",
      "   integration_id  INT_NUM  WAVELENGTH_0  WAVELENGTH_1  WAVELENGTH_2  \\\n",
      "0               0        1      0.551655      0.555024      0.558463   \n",
      "1               1        2      0.551655      0.555024      0.558463   \n",
      "2               2        3      0.551655      0.555024      0.558463   \n",
      "3               3        4      0.551655      0.555024      0.558463   \n",
      "4               4        5      0.551655      0.555024      0.558463   \n",
      "\n",
      "   WAVELENGTH_3  WAVELENGTH_4  WAVELENGTH_5  WAVELENGTH_6  WAVELENGTH_7  ...  \\\n",
      "0      0.561964      0.565522      0.569151      0.572851      0.576618  ...   \n",
      "1      0.561964      0.565522      0.569151      0.572851      0.576618  ...   \n",
      "2      0.561964      0.565522      0.569151      0.572851      0.576618  ...   \n",
      "3      0.561964      0.565522      0.569151      0.572851      0.576618  ...   \n",
      "4      0.561964      0.565522      0.569151      0.572851      0.576618  ...   \n",
      "\n",
      "   NPIXELS_430  NPIXELS_431  N_ALONGDISP  SEGMENT       MJD-BEG       MJD-AVG  \\\n",
      "0          0.0          0.0          432        1  59770.641369  59770.641375   \n",
      "1          0.0          0.0          432        1  59770.641385  59770.641391   \n",
      "2          0.0          0.0          432        1  59770.641401  59770.641407   \n",
      "3          0.0          0.0          432        1  59770.641417  59770.641423   \n",
      "4          0.0          0.0          432        1  59770.641433  59770.641439   \n",
      "\n",
      "        MJD-END       TDB-BEG       TDB-MID       TDB-END  \n",
      "0  59770.641382  59770.644014  59770.644020  59770.644027  \n",
      "1  59770.641398  59770.644030  59770.644036  59770.644043  \n",
      "2  59770.641414  59770.644045  59770.644052  59770.644059  \n",
      "3  59770.641430  59770.644061  59770.644068  59770.644075  \n",
      "4  59770.641446  59770.644077  59770.644084  59770.644091  \n",
      "\n",
      "[5 rows x 7786 columns]\n",
      "\n",
      "Column names (first 10):\n",
      "['integration_id', 'INT_NUM', 'WAVELENGTH_0', 'WAVELENGTH_1', 'WAVELENGTH_2', 'WAVELENGTH_3', 'WAVELENGTH_4', 'WAVELENGTH_5', 'WAVELENGTH_6', 'WAVELENGTH_7']\n",
      "\n",
      "Data types:\n",
      "float64    7350\n",
      "int64       436\n",
      "Name: count, dtype: int64\n",
      "\n",
      "======================================================================\n",
      "COMBINING ALL VERSIONS\n",
      "======================================================================\n",
      "Loaded version 1: (6100, 7787)\n",
      "Loaded version 2: (6100, 7787)\n",
      "Loaded version 3: (6100, 7787)\n",
      "Loaded version 4: (3200, 7787)\n",
      "\n",
      "Combined file saved: wasp39_extracted_data\\combined_spectrum.csv\n",
      "Combined shape: (21500, 7787)\n",
      "Versions included: [np.int64(1), np.int64(2), np.int64(3), np.int64(4)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extract all EXTRACT1D versions from JWST WASP-39b NIRSpec PRISM data\n",
    "Converts FITS data to CSV format for each detector/version\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_fits_to_csv(fits_file, output_dir='extracted_data'):\n",
    "    \"\"\"\n",
    "    Extract all EXTRACT1D versions from FITS file and save as CSV\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fits_file : str\n",
    "        Path to the FITS file\n",
    "    output_dir : str\n",
    "        Directory to save CSV files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Opening FITS file: {fits_file}\")\n",
    "    \n",
    "    with fits.open(fits_file) as hdul:\n",
    "        # Print file structure\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"FITS FILE STRUCTURE\")\n",
    "        print(\"=\"*70)\n",
    "        hdul.info()\n",
    "        \n",
    "        # Extract INT_TIMES (integration timing information)\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EXTRACTING INTEGRATION TIMES\")\n",
    "        print(\"=\"*70)\n",
    "        int_times_data = hdul[1].data\n",
    "        int_times_df = pd.DataFrame(int_times_data)\n",
    "        int_times_file = os.path.join(output_dir, 'integration_times.csv')\n",
    "        int_times_df.to_csv(int_times_file, index=False)\n",
    "        print(f\"Saved: {int_times_file}\")\n",
    "        print(f\"Shape: {int_times_df.shape}\")\n",
    "        print(f\"Columns: {list(int_times_df.columns)}\")\n",
    "        \n",
    "        # Extract each EXTRACT1D version\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"EXTRACTING SPECTRA FROM ALL VERSIONS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        extract_hdu_indices = [2, 3, 4, 5]  # EXTRACT1D HDUs\n",
    "        \n",
    "        for version_num, hdu_idx in enumerate(extract_hdu_indices, start=1):\n",
    "            try:\n",
    "                hdu = hdul[hdu_idx]\n",
    "                data = hdu.data\n",
    "                header = hdu.header\n",
    "                \n",
    "                print(f\"\\n--- EXTRACT1D Version {version_num} (HDU {hdu_idx}) ---\")\n",
    "                print(f\"Rows: {len(data)}, Columns: {len(data.dtype.names)}\")\n",
    "                \n",
    "                # Get column names from FITS\n",
    "                col_names = data.dtype.names\n",
    "                print(f\"Column names: {col_names[:5]}... (showing first 5)\")\n",
    "                \n",
    "                # Create DataFrame\n",
    "                df_dict = {}\n",
    "                df_dict['integration_id'] = np.arange(len(data))\n",
    "                \n",
    "                # Extract each column\n",
    "                for col_name in col_names:\n",
    "                    col_data = data[col_name]\n",
    "                    \n",
    "                    # If column is array-like (wavelengths, flux, errors)\n",
    "                    if len(col_data.shape) > 1:\n",
    "                        n_wavelengths = col_data.shape[1]\n",
    "                        for i in range(n_wavelengths):\n",
    "                            df_dict[f'{col_name}_{i}'] = col_data[:, i]\n",
    "                    else:\n",
    "                        # Scalar column\n",
    "                        df_dict[col_name] = col_data\n",
    "                \n",
    "                df = pd.DataFrame(df_dict)\n",
    "                \n",
    "                # Save to CSV\n",
    "                output_file = os.path.join(output_dir, f'extract1d_version_{version_num}.csv')\n",
    "                df.to_csv(output_file, index=False)\n",
    "                print(f\"Saved: {output_file}\")\n",
    "                print(f\"Shape: {df.shape}\")\n",
    "                print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "                \n",
    "            except IndexError:\n",
    "                print(f\"HDU {hdu_idx} not found, skipping...\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing HDU {hdu_idx}: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXTRACTION COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"All files saved to: {output_dir}/\")\n",
    "    print(\"\\nGenerated files:\")\n",
    "    for file in sorted(os.listdir(output_dir)):\n",
    "        filepath = os.path.join(output_dir, file)\n",
    "        file_size = os.path.getsize(filepath) / 1024**2\n",
    "        print(f\"  - {file} ({file_size:.2f} MB)\")\n",
    "\n",
    "\n",
    "def load_and_inspect_csv(csv_file):\n",
    "    \"\"\"\n",
    "    Load and inspect a generated CSV file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        Path to CSV file\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    print(f\"\\nInspecting: {csv_file}\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nColumn names (first 10):\")\n",
    "    print(list(df.columns)[:10])\n",
    "    print(f\"\\nData types:\")\n",
    "    print(df.dtypes.value_counts())\n",
    "\n",
    "\n",
    "def combine_all_versions(output_dir='extracted_data', combined_file='combined_spectrum.csv'):\n",
    "    \"\"\"\n",
    "    Combine all extracted versions into a single master file\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    output_dir : str\n",
    "        Directory containing extracted CSV files\n",
    "    combined_file : str\n",
    "        Output filename for combined data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMBINING ALL VERSIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_dfs = []\n",
    "    \n",
    "    for version_num in range(1, 5):\n",
    "        csv_file = os.path.join(output_dir, f'extract1d_version_{version_num}.csv')\n",
    "        try:\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df['source_version'] = version_num  # Add version tracking\n",
    "            all_dfs.append(df)\n",
    "            print(f\"Loaded version {version_num}: {df.shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Version {version_num} file not found, skipping...\")\n",
    "    \n",
    "    if all_dfs:\n",
    "        combined_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "        output_path = os.path.join(output_dir, combined_file)\n",
    "        combined_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nCombined file saved: {output_path}\")\n",
    "        print(f\"Combined shape: {combined_df.shape}\")\n",
    "        print(f\"Versions included: {sorted(combined_df['source_version'].unique())}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the path to your FITS file\n",
    "    fits_file = 'jw01366-o004_t001_nirspec_clear-prism-s1600a1-sub512_x1dints.fits'\n",
    "    output_directory = 'wasp39_extracted_data'\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(fits_file):\n",
    "        print(f\"Error: FITS file not found: {fits_file}\")\n",
    "        print(\"Please download the file from MAST or adjust the path\")\n",
    "    else:\n",
    "        # Extract all versions\n",
    "        extract_fits_to_csv(fits_file, output_directory)\n",
    "        \n",
    "        # Optional: Inspect one of the files\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"SAMPLE INSPECTION\")\n",
    "        print(\"=\"*70)\n",
    "        sample_csv = os.path.join(output_directory, 'extract1d_version_1.csv')\n",
    "        if os.path.exists(sample_csv):\n",
    "            load_and_inspect_csv(sample_csv)\n",
    "        \n",
    "        # Optional: Combine all versions\n",
    "        combine_all_versions(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb8519-3464-48f4-8901-47b3afc95eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
